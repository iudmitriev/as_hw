{
    "name": "deepspeech2_200_epochs",
    "n_gpu": 1,
    "preprocessing": {
      "sr": 16000,
      "spectrogram": {
        "type": "MelSpectrogram",
        "args": {
        }
      },
      "log_spec": true
    },
    "augmentations": {
      "wave": [],
      "spectrogram": []
    },
    "arch": {
      "type": "DeepSpeech2Model",
      "args": {
        "n_feats": 128,
        "bidirectional": true
      }
    },
    "text_encoder": {
        "type": "CTCCharTextEncoderWithLM",
        "args": {
            "alpha": 0.5,
            "beta" : 1
        }
    },
    "data": {
      "test-other": {
        "batch_size": 32,
        "num_workers": 5,
        "datasets": [
          {
            "type": "LibrispeechDataset",
            "args": {
              "part": "test-other"
            }
          }
        ]
      },
      "test": {
        "batch_size": 2,
        "num_workers": 5,
        "datasets": [
          {
            "type": "LibrispeechDataset",
            "args": {
              "part": "test-clean",
	      "limit": 64
            }
          }
        ]
      }
    },
    "loss": {
      "type": "CTCLoss",
      "args": {}
    },
    "metrics": [
      {
        "type": "WERMetricWithLM",
        "args": {
          "name": "WER (with LM)"
        }
      },
      {
        "type": "CERMetricWithLM",
        "args": {
          "name": "CER (with LM)"
        }
      }
    ],
    "trainer": {
      "epochs": 100,
      "save_dir": "saved/",
      "save_period": 5,
      "verbosity": 2,
      "monitor": "min val_loss",
      "early_stop": 500,
      "visualize": "wandb",
      "wandb_project": "asr_project",
      "len_epoch": 500,
      "grad_norm_clip": 10
    }
}
